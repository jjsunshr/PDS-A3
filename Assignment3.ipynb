{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3xQa6VlNAOe"
   },
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "0mG3n0qRNTSA",
    "outputId": "cb0eadbd-b8a8-41b1-e3b4-7f44b47a8804"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242       3  881250949\n",
       "1      186      302       3  891717742\n",
       "2       22      377       1  878887116\n",
       "3      244       51       2  880606923\n",
       "4      166      346       1  886397596"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load MovieLens 100K dataset into a dataframe of pandas\n",
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv('ml-100k/u.data', sep='\\t', names=names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hFJT0QWudp1P"
   },
   "outputs": [],
   "source": [
    "# Select 500 most active users and 500 most active items from the dataset\n",
    "n_most_active_users = 500\n",
    "n_most_active_items = 500\n",
    "\n",
    "user_ids = df.groupby('user_id').count().sort_values(by='rating', ascending=False).head(n_most_active_users).index\n",
    "item_ids = df.groupby('item_id').count().sort_values(by='rating', ascending=False).head(n_most_active_items).index\n",
    "df = df[(df['user_id'].isin(user_ids)) & (df['item_id'].isin(item_ids))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "r012fu0jJkJc"
   },
   "outputs": [],
   "source": [
    "# Map new internal ID for items\n",
    "i_ids = df['item_id'].unique().tolist()\n",
    "item_dict = dict(zip(i_ids, [i for i in range(len(i_ids))]))\n",
    "df['item_id'] = df['item_id'].map(item_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vZ3rlC7jO6WJ"
   },
   "source": [
    "# Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EwS00lvHO-ca",
    "outputId": "f9f3a031-b4e7-439e-c3e3-c165b2286d19"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-fb140fbf3b12>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['user_id'] = train_df['user_id'].map(user_dict)\n",
      "<ipython-input-4-fb140fbf3b12>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  remain_df['user_id'] = remain_df['user_id'].map(user_dict)\n"
     ]
    }
   ],
   "source": [
    "# The number of training users and active users\n",
    "n_training_users = 300\n",
    "n_active_users = n_most_active_users - n_training_users\n",
    "\n",
    "# The number of GIVEN ratings for active users\n",
    "GIVEN = 20\n",
    "\n",
    "# Randomly select users from the most active users as training set\n",
    "random_uids = np.random.choice(df.user_id.unique(), n_training_users, replace=False)\n",
    "train_df = df[df['user_id'].isin(random_uids)]\n",
    "# Map new internal ID for all users in the training set\n",
    "u_ids = train_df['user_id'].unique().tolist()\n",
    "user_dict = dict(zip(u_ids, [i for i in range(len(u_ids))]))\n",
    "train_df['user_id'] = train_df['user_id'].map(user_dict)\n",
    "\n",
    "# The rest of users are active users for testing\n",
    "remain_df = df[~df['user_id'].isin(random_uids)]\n",
    "# Map new internal ID for all active users\n",
    "u_ids = remain_df['user_id'].unique().tolist()\n",
    "user_dict = dict(zip(u_ids, [i for i in range(len(u_ids))]))\n",
    "remain_df['user_id'] = remain_df['user_id'].map(user_dict)\n",
    "\n",
    "# Randomly select GIVEN ratings for active users\n",
    "active_df = remain_df.groupby('user_id').sample(n=GIVEN, random_state=1024)\n",
    "\n",
    "test_df = remain_df[~remain_df.index.isin(active_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c-ke62G3jiYb",
    "outputId": "1c135984-edb4-4f2b-fc73-9225d86a0c38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(item_id  0    1    2    3    4    5    6    7    8    9    ...  490  491  492  \\\n",
       " user_id                                                    ...                  \n",
       " 0        3.0  0.0  0.0  0.0  0.0  0.0  0.0  4.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 1        0.0  2.0  0.0  4.0  0.0  4.0  4.0  0.0  0.0  2.0  ...  0.0  4.0  4.0   \n",
       " 2        4.0  0.0  0.0  2.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 3        4.0  0.0  5.0  0.0  0.0  3.0  4.0  2.0  0.0  2.0  ...  0.0  2.0  0.0   \n",
       " 4        4.0  0.0  5.0  0.0  1.0  0.0  3.0  2.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       " 295      4.0  0.0  4.0  0.0  0.0  4.0  3.0  4.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 296      0.0  0.0  0.0  0.0  0.0  0.0  0.0  5.0  4.0  5.0  ...  0.0  0.0  4.0   \n",
       " 297      0.0  0.0  5.0  4.0  0.0  1.0  0.0  0.0  0.0  1.0  ...  0.0  0.0  0.0   \n",
       " 298      0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  3.0  4.0  0.0   \n",
       " 299      0.0  0.0  0.0  3.0  0.0  0.0  0.0  4.0  0.0  0.0  ...  0.0  0.0  5.0   \n",
       " \n",
       " item_id  493  494  495  496  497  498  499  \n",
       " user_id                                     \n",
       " 0        0.0  0.0  0.0  4.0  0.0  3.0  0.0  \n",
       " 1        0.0  3.0  3.0  0.0  0.0  0.0  0.0  \n",
       " 2        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 3        0.0  0.0  0.0  0.0  4.0  0.0  0.0  \n",
       " 4        4.0  1.0  0.0  0.0  0.0  0.0  2.0  \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  \n",
       " 295      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 296      0.0  4.0  2.0  3.0  0.0  0.0  0.0  \n",
       " 297      0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       " 298      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 299      0.0  0.0  3.0  0.0  0.0  0.0  0.0  \n",
       " \n",
       " [300 rows x 500 columns],\n",
       " item_id  0    1    2    3    4    5    6    7    8    9    ...  490  491  492  \\\n",
       " user_id                                                    ...                  \n",
       " 0        0.0  0.0  4.0  0.0  0.0  0.0  0.0  4.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 1        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 2        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 3        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 4        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  3.0  0.0   \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       " 195      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 196      0.0  0.0  0.0  0.0  0.0  0.0  0.0  4.0  0.0  0.0  ...  0.0  0.0  4.0   \n",
       " 197      0.0  0.0  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 198      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 199      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " \n",
       " item_id  493  494  495  496  497  498  499  \n",
       " user_id                                     \n",
       " 0        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 1        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 2        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 3        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 4        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  \n",
       " 195      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 196      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 197      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 198      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 199      5.0  0.0  0.0  3.0  0.0  0.0  0.0  \n",
       " \n",
       " [200 rows x 500 columns],\n",
       " item_id  0    1    2    3    4    5    6    7    8    9    ...  490  491  492  \\\n",
       " user_id                                                    ...                  \n",
       " 0        0.0  0.0  0.0  4.0  4.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 1        0.0  0.0  0.0  0.0  5.0  0.0  0.0  0.0  0.0  4.0  ...  0.0  0.0  0.0   \n",
       " 2        3.0  0.0  4.0  0.0  0.0  3.0  2.0  2.0  0.0  5.0  ...  0.0  4.0  0.0   \n",
       " 3        0.0  4.0  0.0  0.0  0.0  0.0  3.0  0.0  0.0  4.0  ...  0.0  0.0  3.0   \n",
       " 4        4.0  0.0  5.0  0.0  0.0  0.0  4.0  2.0  0.0  2.0  ...  0.0  0.0  0.0   \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       " 195      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 196      4.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 197      4.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 198      0.0  0.0  0.0  5.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 199      0.0  0.0  0.0  0.0  0.0  0.0  0.0  3.0  3.0  0.0  ...  4.0  0.0  0.0   \n",
       " \n",
       " item_id  493  494  495  496  497  498  499  \n",
       " user_id                                     \n",
       " 0        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 1        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 2        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 3        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 4        1.0  0.0  0.0  0.0  0.0  0.0  3.0  \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  \n",
       " 195      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 196      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 197      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 198      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 199      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " \n",
       " [200 rows x 500 columns])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the format of datasets to matrices\n",
    "df_zeros = pd.DataFrame({'user_id': np.tile(np.arange(0, n_training_users), n_most_active_items), 'item_id': np.repeat(np.arange(0, n_most_active_items), n_training_users), 'rating': 0})\n",
    "train_ds = df_zeros.merge(train_df, how='left', on=['user_id', 'item_id']).fillna(0.).pivot_table(values='rating_y', index='user_id', columns='item_id')\n",
    "\n",
    "df_zeros = pd.DataFrame({'user_id': np.tile(np.arange(0, n_active_users), n_most_active_items), 'item_id': np.repeat(np.arange(0, n_most_active_items), n_active_users), 'rating': 0})\n",
    "active_ds = df_zeros.merge(active_df, how='left', on=['user_id', 'item_id']).fillna(0.).pivot_table(values='rating_y', index='user_id', columns='item_id')\n",
    "test_ds = df_zeros.merge(test_df, how='left', on=['user_id', 'item_id']).fillna(0.).pivot_table(values='rating_y', index='user_id', columns='item_id')\n",
    "\n",
    "train_ds, active_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "yElYv2TDKKGu"
   },
   "outputs": [],
   "source": [
    "# Predicting All Missing Data in training set\n",
    "imputed_train_ds = train_ds.values.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iy4FurbHD4dt"
   },
   "source": [
    "# Your implementation to predict the missing values\n",
    "(Put all your implementation for your algorithm in the following cell only to handle the missing values; )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zYh1bVd0ncz3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-5325d61d222a>:92: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  load_pc[i][j] = A / (math.sqrt(B) * math.sqrt(C))\n"
     ]
    }
   ],
   "source": [
    "## Put all your implementation for your solutioin in this cell only to predict the missing values; \n",
    "## NOTE 1: DO NOT change anything in the rest of the cells in this framework, \n",
    "## otherwise the changes might cause errors and make your implementation invalid.\n",
    "\n",
    "## Note 2: \n",
    "## The user-item rating matrix is imputed_train_ds, \n",
    "## and the missing values are those 0s in imputed_train_ds. \n",
    "## You are required to predict them by using the solution in the given report. \n",
    "\n",
    "## The following parameters are required in the given report, \n",
    "## which is named \"Effective Missing Data Prediction for Collaborative Filtering\", \n",
    "## and you will need to use them. But, please do not change their values. \n",
    "import math\n",
    "LAMBDA = 0.7    # λ\n",
    "GAMMA = 10      # γ\n",
    "DELTA = 10      # δ\n",
    "ITA = 0.7       # η\n",
    "THETA = 0.7     # θ\n",
    "EPSILON = 1e-9\n",
    "# Predicting All Missing Data in training set\n",
    "imputed_train_ds = train_ds.values.copy()\n",
    "# For users\n",
    "def simUser(data,para,threshold):\n",
    "    load_ar = np.array(data)\n",
    "    lie,hang=load_ar.shape\n",
    "    # Save user's mean values\n",
    "    user_mean=[0 for k in range(lie)]\n",
    "    index=[k for k in range(hang)]\n",
    "    load_pc=np.zeros((lie,lie))\n",
    "    # Calculate the weighting matrix\n",
    "    weight=np.zeros((lie,lie))\n",
    "    for i in range(lie):\n",
    "        for j in range(i,lie):\n",
    "            if i==j:\n",
    "                load_pc[i][j]=1.0\n",
    "                weight[i][j]=min((load_ar[i,:]!=0).sum(),para)*1.0/para\n",
    "            else:\n",
    "                # User common evaluation's index\n",
    "                i_index=np.array(index)[(load_ar[i]!=0)]\n",
    "                j_index=np.array(index)[(load_ar[j]!=0)]\n",
    "                commom=list(set(i_index)&set(j_index))\n",
    "                mean_i=sum(load_ar[i])*1.0/len(i_index)\n",
    "                user_mean[i]=mean_i\n",
    "                mean_j=sum(load_ar[j])*1.0/len(j_index)\n",
    "                A=0\n",
    "                B=0\n",
    "                C=0\n",
    "                for each in commom:\n",
    "                    A+=(load_ar[i][each]-mean_i)*(load_ar[j][each]-mean_j)\n",
    "                    B+=(load_ar[i][each]-mean_i)**2\n",
    "                    C+=(load_ar[j][each]-mean_j)**2\n",
    "                if len(commom)!=0:\n",
    "                    load_pc[i][j]=A/(math.sqrt(B)*math.sqrt(C))\n",
    "                    load_pc[j][i]=load_pc[i][j]\n",
    "                n=len(commom)\n",
    "                weight[i][j]=min(n,para)*1.0/para\n",
    "                weight[j][i]=weight[i][j]\n",
    "    User_User=weight*load_pc\n",
    "    return User_User,user_mean\n",
    "# For item\n",
    "def simItem(data,para,threshold):\n",
    "    load_ar = np.array(data)\n",
    "    load_ar=load_ar.T\n",
    "    lie, hang = load_ar.shape\n",
    "    # Save item's mean value\n",
    "    item_mean = [0 for k in range(lie)]\n",
    "    index = [k for k in range(hang)]\n",
    "    load_pc = np.zeros((lie, lie))\n",
    "    # Calculate the weight matrix\n",
    "    weight = np.zeros((lie, lie))\n",
    "    for i in range(lie):\n",
    "        for j in range(i, lie):\n",
    "            if i == j:\n",
    "                load_pc[i][j] = 1.0\n",
    "                weight[i][j] = min((load_ar[i, :] != 0).sum(), para) * 1.0 / para\n",
    "            else:\n",
    "                # Item common evaluation 's index\n",
    "                i_index = np.array(index)[(load_ar[i] != 0)]\n",
    "                j_index = np.array(index)[(load_ar[j] != 0)]\n",
    "                commom = list(set(i_index) & set(j_index))\n",
    "                mean_i = sum(load_ar[i]) * 1.0 / len(i_index)\n",
    "                item_mean[i]=mean_i\n",
    "                mean_j = sum(load_ar[j]) * 1.0 / len(j_index)\n",
    "                A = 0\n",
    "                B = 0\n",
    "                C = 0\n",
    "                for each in commom:\n",
    "                    A += (load_ar[i][each] - mean_i) * (load_ar[j][each] - mean_j)\n",
    "                    B += (load_ar[i][each] - mean_i) ** 2\n",
    "                    C += (load_ar[j][each] - mean_j) ** 2\n",
    "                if len(commom) != 0:\n",
    "                    load_pc[i][j] = A / (math.sqrt(B) * math.sqrt(C))\n",
    "                    load_pc[j][i] = load_pc[i][j]\n",
    "                n = len(commom)\n",
    "                weight[i][j] = min(n, para) * 1.0 / para\n",
    "                weight[j][i] = weight[i][j]\n",
    "    item_item = weight * load_pc\n",
    "    # print(item_item)\n",
    "    return item_item,item_mean\n",
    "\n",
    "LAMBDA = 0.7    # λ\n",
    "GAMMA = 10      # γ\n",
    "DELTA = 10      # δ\n",
    "ITA = 0.7       # η\n",
    "THETA = 0.7     # θ\n",
    "EPSILON = 1e-9\n",
    "# For the missing values:\n",
    "# Firstly, will generate similar users and similar users will be calculated by the PCC for users. \n",
    "# And will generate similar items and similar items will be calculated by the PCC for items. \n",
    "# Only if there are neither similar users nor similar items,the missing values will be still 'missing'\n",
    "user2user,user_mean=simUser(train_ds,GAMMA,ITA)\n",
    "u_index=[k for k in range(len(user_mean))]\n",
    "similaryUser=user2user>ITA\n",
    "item2item,item_mean=simItem(train_ds,DELTA,THETA)\n",
    "i_index=[k for k in range(len(item_mean))]\n",
    "similaryItem=item2item>THETA\n",
    "# Fill in missing values\n",
    "# Original evaluation matrix is train_ds\n",
    "def predict_values(data,type):\n",
    "    rating_matrix=np.array(data)\n",
    "    for u in range(len(rating_matrix)):\n",
    "        for i in range(len(rating_matrix[0])):\n",
    "            # Using ==0 when evaluation part is missing,it will need to fill in\n",
    "            if rating_matrix[u][i]==0:\n",
    "                # Get the similar users and items\n",
    "                sim_user_u=np.array(u_index)[similaryUser[u]]\n",
    "                sim_item_i=np.array(i_index)[similaryItem[i]]\n",
    "                u_score = 0\n",
    "                i_score=0\n",
    "                # Based on the users' score\n",
    "                if len(sim_user_u)>1:\n",
    "                    A=0\n",
    "                    B=0\n",
    "                    for each in sim_user_u:\n",
    "                        if each!=u:\n",
    "                            A+=user2user[u][each]*(rating_matrix[each][i]-user_mean[each])\n",
    "                            B+=user2user[u][each]\n",
    "                    u_score+=user_mean[u]+A*1.0/B\n",
    "                # Based on the items' score\n",
    "                if len(sim_item_i)>1:\n",
    "                    A=0\n",
    "                    B=0\n",
    "                    for each in sim_item_i:\n",
    "                        if each!=i:\n",
    "                            A+=item2item[i][each]*(rating_matrix[u][each]-item_mean[each])\n",
    "                            B+=item2item[i][each]\n",
    "                # If there are neither similar users nor similar items\n",
    "                if u_score*i_score==0:\n",
    "                    if (u_score+i_score)!=0:\n",
    "                        rating_matrix[u][i]=u_score+i_score\n",
    "                    else:\n",
    "                        if type=='active':\n",
    "                            rating_matrix[u][i]=LAMBDA*user_mean[u]+(1-LAMBDA)*item_mean[i]\n",
    "                else:\n",
    "                    rating_matrix[u][i]=LAMBDA*u_score+(1-LAMBDA)*i_score\n",
    "    return rating_matrix\n",
    "imputed_train_ds=predict_values(imputed_train_ds,'active')\n",
    "imputed_train_ds=pd.DataFrame(imputed_train_ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbOfVWTV_Aij"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Txs8YjwTzuSP"
   },
   "source": [
    "### Compute Pearson Correlation Coefficient of All Pairs of Items between active set and imputed training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "KoOgX_axKKGw",
    "outputId": "37a7adbd-e0d6-4375-e28c-3940977896f2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.472449</td>\n",
       "      <td>3.723404</td>\n",
       "      <td>3.592857</td>\n",
       "      <td>3.506250</td>\n",
       "      <td>3.440000</td>\n",
       "      <td>3.665789</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.381250</td>\n",
       "      <td>3.529641</td>\n",
       "      <td>...</td>\n",
       "      <td>3.312500</td>\n",
       "      <td>3.342683</td>\n",
       "      <td>3.578261</td>\n",
       "      <td>3.661111</td>\n",
       "      <td>3.395652</td>\n",
       "      <td>3.080769</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.478571</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.813407</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.845227</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.628073</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.655694</td>\n",
       "      <td>3.503073</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.434323</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.782934</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.237448</td>\n",
       "      <td>3.600395</td>\n",
       "      <td>3.415573</td>\n",
       "      <td>2.571823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.796199</td>\n",
       "      <td>4.047154</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.830000</td>\n",
       "      <td>3.763750</td>\n",
       "      <td>3.989539</td>\n",
       "      <td>3.857621</td>\n",
       "      <td>3.705000</td>\n",
       "      <td>3.853391</td>\n",
       "      <td>...</td>\n",
       "      <td>3.636250</td>\n",
       "      <td>3.666433</td>\n",
       "      <td>3.902011</td>\n",
       "      <td>3.984861</td>\n",
       "      <td>3.719402</td>\n",
       "      <td>3.404519</td>\n",
       "      <td>3.439375</td>\n",
       "      <td>3.802321</td>\n",
       "      <td>3.617500</td>\n",
       "      <td>2.773750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.397730</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.518138</td>\n",
       "      <td>3.431531</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.306531</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.237781</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.503542</td>\n",
       "      <td>3.586392</td>\n",
       "      <td>3.320933</td>\n",
       "      <td>3.006050</td>\n",
       "      <td>3.040906</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.219031</td>\n",
       "      <td>2.375281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.563926</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.684334</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.531477</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.472727</td>\n",
       "      <td>3.621118</td>\n",
       "      <td>...</td>\n",
       "      <td>3.403977</td>\n",
       "      <td>3.434160</td>\n",
       "      <td>3.669738</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.172247</td>\n",
       "      <td>3.207102</td>\n",
       "      <td>3.570049</td>\n",
       "      <td>3.385227</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.685730</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.806138</td>\n",
       "      <td>3.719531</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.594531</td>\n",
       "      <td>3.742922</td>\n",
       "      <td>...</td>\n",
       "      <td>3.525781</td>\n",
       "      <td>3.555964</td>\n",
       "      <td>3.791542</td>\n",
       "      <td>3.874392</td>\n",
       "      <td>3.608933</td>\n",
       "      <td>3.294050</td>\n",
       "      <td>3.328906</td>\n",
       "      <td>3.691853</td>\n",
       "      <td>3.507031</td>\n",
       "      <td>2.663281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2.126935</td>\n",
       "      <td>0.120404</td>\n",
       "      <td>0.120404</td>\n",
       "      <td>0.120404</td>\n",
       "      <td>0.120404</td>\n",
       "      <td>0.120404</td>\n",
       "      <td>0.120404</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.720092</td>\n",
       "      <td>0.120404</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.120404</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.706477</td>\n",
       "      <td>0.120404</td>\n",
       "      <td>0.120404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>3.202482</td>\n",
       "      <td>2.983346</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.017147</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.176687</td>\n",
       "      <td>3.044768</td>\n",
       "      <td>2.892147</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.823397</td>\n",
       "      <td>2.853580</td>\n",
       "      <td>3.089158</td>\n",
       "      <td>3.172009</td>\n",
       "      <td>2.906550</td>\n",
       "      <td>2.591667</td>\n",
       "      <td>2.626522</td>\n",
       "      <td>2.989469</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.960897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>3.707493</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.739313</td>\n",
       "      <td>3.608766</td>\n",
       "      <td>3.522159</td>\n",
       "      <td>3.455909</td>\n",
       "      <td>3.681699</td>\n",
       "      <td>3.549780</td>\n",
       "      <td>3.397159</td>\n",
       "      <td>3.545550</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.594170</td>\n",
       "      <td>3.677020</td>\n",
       "      <td>3.411561</td>\n",
       "      <td>3.096678</td>\n",
       "      <td>3.131534</td>\n",
       "      <td>3.494481</td>\n",
       "      <td>3.309659</td>\n",
       "      <td>2.465909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>1.280488</td>\n",
       "      <td>1.022449</td>\n",
       "      <td>1.273404</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.056250</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>1.215789</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.931250</td>\n",
       "      <td>0.280488</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.719512</td>\n",
       "      <td>0.892683</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.211111</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.665625</td>\n",
       "      <td>1.028571</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    3.000000  3.472449  3.723404  3.592857  3.506250  3.440000  3.665789   \n",
       "1    3.813407  2.000000  3.845227  4.000000  3.628073  4.000000  4.000000   \n",
       "2    4.000000  3.796199  4.047154  2.000000  3.830000  3.763750  3.989539   \n",
       "3    4.000000  3.397730  5.000000  3.518138  3.431531  3.000000  4.000000   \n",
       "4    4.000000  3.563926  5.000000  3.684334  1.000000  3.531477  3.000000   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "295  4.000000  3.685730  4.000000  3.806138  3.719531  4.000000  3.000000   \n",
       "296  2.126935  0.120404  0.120404  0.120404  0.120404  0.120404  0.120404   \n",
       "297  3.202482  2.983346  5.000000  4.000000  3.017147  1.000000  3.176687   \n",
       "298  3.707493  1.000000  3.739313  3.608766  3.522159  3.455909  3.681699   \n",
       "299  1.280488  1.022449  1.273404  3.000000  1.056250  0.990000  1.215789   \n",
       "\n",
       "          7         8         9    ...       490       491       492  \\\n",
       "0    4.000000  3.381250  3.529641  ...  3.312500  3.342683  3.578261   \n",
       "1    3.655694  3.503073  2.000000  ...  3.434323  4.000000  4.000000   \n",
       "2    3.857621  3.705000  3.853391  ...  3.636250  3.666433  3.902011   \n",
       "3    2.000000  3.306531  2.000000  ...  3.237781  2.000000  3.503542   \n",
       "4    2.000000  3.472727  3.621118  ...  3.403977  3.434160  3.669738   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "295  4.000000  3.594531  3.742922  ...  3.525781  3.555964  3.791542   \n",
       "296  5.000000  4.000000  5.000000  ...  0.720092  0.120404  4.000000   \n",
       "297  3.044768  2.892147  1.000000  ...  2.823397  2.853580  3.089158   \n",
       "298  3.549780  3.397159  3.545550  ...  3.000000  4.000000  3.594170   \n",
       "299  4.000000  0.931250  0.280488  ... -1.719512  0.892683  5.000000   \n",
       "\n",
       "          493       494       495       496       497       498       499  \n",
       "0    3.661111  3.395652  3.080769  4.000000  3.478571  3.000000  2.450000  \n",
       "1    3.782934  3.000000  3.000000  3.237448  3.600395  3.415573  2.571823  \n",
       "2    3.984861  3.719402  3.404519  3.439375  3.802321  3.617500  2.773750  \n",
       "3    3.586392  3.320933  3.006050  3.040906  4.000000  3.219031  2.375281  \n",
       "4    4.000000  1.000000  3.172247  3.207102  3.570049  3.385227  2.000000  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "295  3.874392  3.608933  3.294050  3.328906  3.691853  3.507031  2.663281  \n",
       "296  0.120404  4.000000  2.000000  3.000000  0.706477  0.120404  0.120404  \n",
       "297  3.172009  2.906550  2.591667  2.626522  2.989469  1.000000  1.960897  \n",
       "298  3.677020  3.411561  3.096678  3.131534  3.494481  3.309659  2.465909  \n",
       "299  1.211111  0.945652  3.000000  0.665625  1.028571  0.843750  0.000000  \n",
       "\n",
       "[300 rows x 500 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_train_ds = pd.DataFrame(imputed_train_ds)\n",
    "imputed_train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eq0uq1aHzu11",
    "outputId": "f6214a46-d63e-4fdc-e7dd-ccaed23b237d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.15297772,  0.06581631,  0.15688735, ...,  0.1923687 ,\n",
       "        -0.02310991,  0.17750324],\n",
       "       [ 0.31341232,  0.09469369, -0.28086223, ...,  0.20444811,\n",
       "        -0.13359192, -0.0419301 ],\n",
       "       [-0.04299883,  0.45597917,  0.13703922, ...,  0.3567764 ,\n",
       "         0.54339542,  0.24159328],\n",
       "       ...,\n",
       "       [-0.22425133,  0.27094149,  0.22220861, ...,  0.08732157,\n",
       "         0.26141798,  0.07121421],\n",
       "       [ 0.07154787, -0.07056512, -0.05950958, ...,  0.1512259 ,\n",
       "         0.34851855,  0.28920255],\n",
       "       [ 0.28989225,  0.3066502 ,  0.25209015, ..., -0.14435992,\n",
       "         0.35720447, -0.29808048]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_user_pearson_corr = np.zeros((active_ds.shape[0], train_ds.shape[0]))\n",
    "\n",
    "# Compute Pearson Correlation Coefficient of All Pairs of Users between active set and imputed training set\n",
    "for i, user_i_vec in enumerate(active_ds.values):\n",
    "    for j, user_j_vec in enumerate(imputed_train_ds.values):\n",
    "        \n",
    "        # ratings corated by the current pair od users\n",
    "        mask_i = user_i_vec > 0\n",
    "        mask_j = user_j_vec > 0\n",
    "\n",
    "        # corrated item index, skip if there are no corrated ratings\n",
    "        corrated_index = np.intersect1d(np.where(mask_i), np.where(mask_j))\n",
    "        if len(corrated_index) == 0:\n",
    "            continue\n",
    "\n",
    "        # average value of user_i_vec and user_j_vec\n",
    "        mean_user_i = np.sum(user_i_vec) / (np.sum(np.clip(user_i_vec, 0, 1)) + EPSILON)\n",
    "        mean_user_j = np.sum(user_j_vec) / (np.sum(np.clip(user_j_vec, 0, 1)) + EPSILON)\n",
    "\n",
    "        # compute pearson corr\n",
    "        user_i_sub_mean = user_i_vec[corrated_index] - mean_user_i\n",
    "        user_j_sub_mean = user_j_vec[corrated_index] - mean_user_j\n",
    "\n",
    "        r_ui_sub_r_i_sq = np.square(user_i_sub_mean)\n",
    "        r_uj_sub_r_j_sq = np.square(user_j_sub_mean)\n",
    "\n",
    "        r_ui_sum_sqrt = np.sqrt(np.sum(r_ui_sub_r_i_sq))\n",
    "        r_uj_sum_sqrt = np.sqrt(np.sum(r_uj_sub_r_j_sq))\n",
    "\n",
    "        sim = np.sum(user_i_sub_mean * user_j_sub_mean) / (r_ui_sum_sqrt * r_uj_sum_sqrt + EPSILON)\n",
    "\n",
    "        # significance weighting\n",
    "        weighted_sim = (min(len(corrated_index), GAMMA) / GAMMA) * sim\n",
    "\n",
    "        active_user_pearson_corr[i][j] = weighted_sim\n",
    "\n",
    "active_user_pearson_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewTnN9kNb8Ys"
   },
   "source": [
    "## Predict Ratings of Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L4ERndYXb8Ys",
    "outputId": "12607670-af61-403a-e4ce-f5e874bf8386"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [3.62769745, 0.        , 4.06601433, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [4.30579592, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 10\n",
    "\n",
    "test_ds_pred = np.zeros_like(test_ds.values)\n",
    "\n",
    "for (i, j), rating in np.ndenumerate(test_ds.values):\n",
    "\n",
    "    if rating > 0:\n",
    "\n",
    "        sim_user_ids = np.argsort(active_user_pearson_corr[i])[-1:-(K + 1):-1]\n",
    "\n",
    "        #==================user-based==================#\n",
    "        # the coefficient values of similar users\n",
    "        sim_val = active_user_pearson_corr[i][sim_user_ids]\n",
    "\n",
    "        # the average value of the current user's ratings\n",
    "        sim_users = imputed_train_ds.values[sim_user_ids]\n",
    "        user_mean = np.sum(active_ds.values[i]) / (np.sum(np.clip(active_ds.values[i], 0, 1)) + EPSILON)\n",
    "        sim_user_mean = np.sum(sim_users, axis=1) / (np.sum(np.clip(sim_users, 0, 1), axis=1) + EPSILON)\n",
    "\n",
    "        # select the users who rated item j\n",
    "        mask_rated_j = sim_users[:, j] > 0\n",
    "        \n",
    "        # sim(u, v) * (r_vj - mean_v)\n",
    "        sim_r_sum_mean = sim_val[mask_rated_j] * (sim_users[mask_rated_j, j] - sim_user_mean[mask_rated_j])\n",
    "        \n",
    "        user_based_pred = user_mean + np.sum(sim_r_sum_mean) / (np.sum(sim_val[mask_rated_j]) + EPSILON)\n",
    "        user_based_pred = np.clip(user_based_pred, 0, 5)\n",
    "\n",
    "        test_ds_pred[i][j] = user_based_pred\n",
    "        \n",
    "test_ds_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUTn4kSFb8ZA"
   },
   "source": [
    "## Compute MAE and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7JCVmexyb8ZA",
    "outputId": "6f650170-e9a6-482a-b695-5fa474d964b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.7663373845314435, RMSE: 0.9805146138857551\n"
     ]
    }
   ],
   "source": [
    "# MAE\n",
    "MAE = np.sum(np.abs(test_ds_pred - test_ds.values)) / np.sum(np.clip(test_ds.values, 0, 1))\n",
    "\n",
    "# RMSE\n",
    "RMSE = np.sqrt(np.sum(np.square(test_ds_pred - test_ds.values)) / np.sum(np.clip(test_ds.values, 0, 1)))\n",
    "\n",
    "print(\"MAE: {}, RMSE: {}\" .format(MAE, RMSE))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment3_framework.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
